{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b61727fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D RGB vector shape: (704, 1248, 3)\n",
      "2D RGB array (partial):\n",
      "[[[164 113  89]\n",
      "  [164 113  89]\n",
      "  [164 113  89]\n",
      "  ...\n",
      "  [ 67  28  15]\n",
      "  [ 67  28  15]\n",
      "  [ 67  28  15]]\n",
      "\n",
      " [[164 113  89]\n",
      "  [164 113  89]\n",
      "  [164 113  89]\n",
      "  ...\n",
      "  [ 67  28  15]\n",
      "  [ 67  28  15]\n",
      "  [ 67  28  15]]\n",
      "\n",
      " [[164 113  89]\n",
      "  [164 113  89]\n",
      "  [164 113  89]\n",
      "  ...\n",
      "  [ 67  28  15]\n",
      "  [ 67  28  15]\n",
      "  [ 67  28  15]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 30  31  82]\n",
      "  [ 31  32  83]\n",
      "  [ 30  33  81]\n",
      "  ...\n",
      "  [  5   2   0]\n",
      "  [  4   1   0]\n",
      "  [  4   1   0]]\n",
      "\n",
      " [[ 33  33  81]\n",
      "  [ 34  34  82]\n",
      "  [ 32  37  79]\n",
      "  ...\n",
      "  [  5   2   0]\n",
      "  [  4   1   0]\n",
      "  [  4   1   0]]\n",
      "\n",
      " [[ 31  31  79]\n",
      "  [ 32  32  80]\n",
      "  [ 30  34  76]\n",
      "  ...\n",
      "  [  5   2   0]\n",
      "  [  4   1   0]\n",
      "  [  4   1   0]]]\n",
      "Sample (first 2 rows, 4 columns):\n",
      "[[[164 113  89]\n",
      "  [164 113  89]\n",
      "  [164 113  89]\n",
      "  [164 113  89]]\n",
      "\n",
      " [[164 113  89]\n",
      "  [164 113  89]\n",
      "  [164 113  89]\n",
      "  [164 113  89]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the video capture\n",
    "cap = cv2.VideoCapture(\"generated-video.mp4\")\n",
    "ret, frame = cap.read()  # Read the first frame\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    # frame shape: (height, width, 3) for RGB\n",
    "    print(\"2D RGB vector shape:\", frame.shape)\n",
    "    print(\"2D RGB array (partial):\")\n",
    "    print(frame)  # This will print the full 2D array with RGB per pixel\n",
    "\n",
    "    # To print a small region for clarity\n",
    "    print(\"Sample (first 2 rows, 4 columns):\")\n",
    "    print(frame[:2, :4, :])  # Displays RGB for a 2x4 pixel region\n",
    "else:\n",
    "    print(\"Failed to read video.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78555b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center pixel coordinates: (624, 352)\n",
      "Center pixel color (RGB): [ 86 223  66]\n"
     ]
    }
   ],
   "source": [
    "# Find the color of the center pixel in the frame\n",
    "height, width, _ = frame.shape\n",
    "center_y = height // 2\n",
    "center_x = width // 2\n",
    "center_pixel = frame[center_y, center_x]\n",
    "print(f\"Center pixel coordinates: ({center_x}, {center_y})\")\n",
    "print(f\"Center pixel color (RGB): {center_pixel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3f26d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as frame_with_target_color_replaced.png\n"
     ]
    }
   ],
   "source": [
    "# Replace pixels close to color (86, 223, 66) with white\n",
    "target_color = np.array([86, 223, 66])\n",
    "tolerance = 15\n",
    "lower = target_color - tolerance\n",
    "upper = target_color + tolerance\n",
    "\n",
    "# Create mask for target color range\n",
    "mask = cv2.inRange(frame, lower, upper)\n",
    "\n",
    "# Replace matching pixels with white\n",
    "frame[mask > 0] = [255, 255, 255]\n",
    "\n",
    "# Save the modified frame as an image\n",
    "cv2.imwrite(\"frame_with_target_color_replaced.png\", frame)\n",
    "print(\"Saved as frame_with_target_color_replaced.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0685465f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest white rectangle coordinates:\n",
      "Top Left: (494, 236)\n",
      "Top Right: (783, 236)\n",
      "Bottom Left: (494, 424)\n",
      "Bottom Right: (783, 424)\n",
      "Area: 54810\n"
     ]
    }
   ],
   "source": [
    "# Find the largest rectangle of white pixels (255, 255, 255) in the frame\n",
    "white_mask = np.all(frame == [255, 255, 255], axis=-1).astype(np.uint8)\n",
    "\n",
    "# Use OpenCV to find contours of white regions\n",
    "contours, _ = cv2.findContours(white_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "max_area = 0\n",
    "largest_rect = None\n",
    "\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    area = w * h\n",
    "    if area > max_area:\n",
    "        max_area = area\n",
    "        largest_rect = (x, y, x + w - 1, y + h - 1)  # (x_min, y_min, x_max, y_max)\n",
    "\n",
    "if largest_rect:\n",
    "    x_min, y_min, x_max, y_max = largest_rect\n",
    "    top_left = (x_min, y_min)\n",
    "    top_right = (x_max, y_min)\n",
    "    bottom_left = (x_min, y_max)\n",
    "    bottom_right = (x_max, y_max)\n",
    "    print(f\"Largest white rectangle coordinates:\")\n",
    "    print(f\"Top Left: {top_left}\")\n",
    "    print(f\"Top Right: {top_right}\")\n",
    "    print(f\"Bottom Left: {bottom_left}\")\n",
    "    print(f\"Bottom Right: {bottom_right}\")\n",
    "    print(f\"Area: {max_area}\")\n",
    "else:\n",
    "    print(\"No white rectangle found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eb8b076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as video_with_white_rectangle.mp4\n"
     ]
    }
   ],
   "source": [
    "# Replace all pixels within the largest white rectangle in every frame of the video with white pixels\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(\"generated-video.mp4\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = None\n",
    "\n",
    "largest_rect = (494, 236, 783, 424)\n",
    "\n",
    "# Use the coordinates from previous cell (update these if needed)\n",
    "x_min, y_min, x_max, y_max = largest_rect  # Make sure this is set from previous cell\n",
    "\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "out = cv2.VideoWriter(\"video_with_white_rectangle.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "for i in range(frame_count):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Replace rectangle region with white\n",
    "    frame[y_min:y_max+1, x_min:x_max+1] = [255, 255, 255]\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"Saved as video_with_white_rectangle.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c8967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to write screensaver-01.mp4\n",
      "Finished writing screensaver-01.mp4\n",
      "Finished writing screensaver-01.mp4\n"
     ]
    }
   ],
   "source": [
    "# Apply an arbitrary image to the detected rectangle for every frame in the video\n",
    "# This uses the helper in apply_image_to_video.py which resizes and pads the image\n",
    "from video_processing import apply_image_to_video\n",
    "\n",
    "video_path = 'generated-video.mp4'\n",
    "image_path = 'creative-01.jpg'  # any image you want to place\n",
    "rect = (494, 236, 783, 424)  # (x_min, y_min, x_max, y_max)\n",
    "out_path = 'screensaver-01.mp4'\n",
    "\n",
    "print('Starting to write', out_path)\n",
    "apply_image_to_video(video_path, image_path, rect, out_path)\n",
    "print('Finished writing', out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005318a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting per-frame processing on input-video-03.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished; wrote output-31.mp4\n"
     ]
    }
   ],
   "source": [
    "# Run per-frame detection and place an image into detected rectangles for each frame\n",
    "from video_processing import apply_image_to_video_per_frame\n",
    "\n",
    "video_path = 'input-video-03.mp4'\n",
    "image_path = 'creative-02.png'\n",
    "out_path = 'output-31.mp4'\n",
    "\n",
    "print('Starting per-frame processing on', video_path)\n",
    "apply_image_to_video_per_frame(video_path, image_path, (50,225,60), out_path, tolerance=20, min_area=1000)\n",
    "print('Finished; wrote', out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab565fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
